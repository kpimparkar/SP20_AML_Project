{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Custome-transformers\" data-toc-modified-id=\"Custome-transformers-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Custome transformers</a></span></li><li><span><a href=\"#Pipeline-creation\" data-toc-modified-id=\"Pipeline-creation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pipeline creation</a></span></li><li><span><a href=\"#Execution-of-pipeline\" data-toc-modified-id=\"Execution-of-pipeline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Execution of pipeline</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_location = r\"C:/Study/IUMSDS/Spring2020/I526_Applied_ML/Project/dataset/\"\n",
    "datafile = \"previous_application.csv\"\n",
    "\n",
    "df_prev_app = pd.read_csv(os.path.join(data_location, datafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custome transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    FeatureAdder class for 'previous_applications' dataset of HCDR project. Added features:\n",
    "    1) TIME: Early_morning [0-8], morning[9-12], afternoon[13-17], evening[18-23]  \n",
    "    2) CREDIT_TO_APP_RATIO: AMT_CREDIT/AMT_APPLICATION \n",
    "    3) APPLIED_EXTRA: AMT_APPLICATION - AMT_GOODS_PRICE \n",
    "    4) WEEKDAY: mon-tue STARTofWK, wed-thu-fri MidWk, sat-sun EndWk\n",
    "\n",
    "    Input: pd.DataFrame \n",
    "    Output: pd.DataFrame with Selected and newly created features \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, selected_features):\n",
    "        self.selected_features = selected_features\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Output : dataframe with selected and engineered features\n",
    "        \"\"\"\n",
    "  \n",
    "        try:\n",
    "            \n",
    "            out_df = X[self.selected_features]\n",
    "            \n",
    "            out_df.loc[out_df['AMT_APPLICATION'] == 0, 'AMT_CREDIT'] = 0 \n",
    "            out_df['CREDIT_TO_APP_RATIO'] = out_df['AMT_CREDIT'] / out_df['AMT_APPLICATION']\n",
    "\n",
    "            out_df['APPLIED_EXTRA'] = '0'\n",
    "            out_df.loc[out_df['AMT_APPLICATION'] > out_df['AMT_GOODS_PRICE'], 'APPLIED_EXTRA'] = '1'\n",
    "\n",
    "            out_df['WEEKDAY'] = out_df['WEEKDAY_APPR_PROCESS_START'].map({'MONDAY':'START','TUESDAY':'START','WEDNESDAY':'MID','THURSDAY':'MID','FRIDAY':'MID','SATURDAY':'END','SUNDAY':'END'})\n",
    "            out_df['TIME'] = out_df['HOUR_APPR_PROCESS_START'].map({0:'EARLY_MORN', 1:'EARLY_MORN', 2:'EARLY_MORN', 3:'EARLY_MORN', 4:'EARLY_MORN', 5:'EARLY_MORN', 6:'EARLY_MORN', 7:'EARLY_MORN', 8:'EARLY_MORN', 9:'MORN', 10:'MORN', 11:'MORN', 12:'MORN', 13:'AFTERNOON', 14:'AFTERNOON', 15:'AFTERNOON', 16:'AFTERNOON', 17:'AFTERNOON', 18:'EVENING', 19:'EVENING', 20:'EVENING', 21:'EVENING', 22:'EVENING', 23:'EVENING'})\n",
    "\n",
    "            out_df.drop(['AMT_GOODS_PRICE','WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START'], axis=1, inplace=True)\n",
    "            \n",
    "            msg = f\"\\n{'='*100}\\nDfFeatureAdder.transform: Success! Transformed DF of {X.shape} to {out_df.shape} shape.\\nFeature list: {list(out_df.columns)}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[92m {msg}\\033[00m\")\n",
    "            \n",
    "            return out_df\n",
    "        except Exception as e:\n",
    "            msg = f\"\\n{'='*100}\\nDfFeatureAdder.transform: Excpetion occurred. Please check - {e}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[91m {msg}\\033[00m\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "class DfImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Based on: sklearn.impute.SimpleImputer\n",
    "    Input: pd.DataFrame of numerical or categorical features\n",
    "    Output: pd.DataFrame\n",
    "    \n",
    "    This class uses sklearn SimpleImputer to replace nulls with values indicated by 'strategy'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_type, feature_list=None, impute_strategy=None, impute_value=None):\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        self.feature_type = feature_type\n",
    "        self.feature_list = feature_list\n",
    "        self.impute_strategy = impute_strategy\n",
    "        self.impute_value = impute_value\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Output : Imputes null values using sklearn.impute.SimpleImputer and returns a pandas dataframe\n",
    "        \"\"\"              \n",
    "        key_attribs = ['SK_ID_CURR','SK_ID_PREV']\n",
    "        if not self.feature_list:\n",
    "            if self.feature_type == \"cat\":\n",
    "                self.feature_list = list(X.select_dtypes(include='object').columns)\n",
    "            elif self.feature_type == \"num\":\n",
    "                self.feature_list = list(X.select_dtypes(exclude='object').columns)\n",
    "        self.feature_list = [i for i in self.feature_list if i not in key_attribs]\n",
    "              \n",
    "        np_array = X[self.feature_list].values\n",
    "        if not self.impute_strategy:\n",
    "            if self.feature_type == \"cat\":\n",
    "                self.impute_strategy = \"constant\"\n",
    "            elif self.feature_type == \"num\":\n",
    "                self.impute_strategy = \"mean\"\n",
    "            else:\n",
    "                print(\"transform(): invalid feature_type - \", self.feature_type)\n",
    "                self.impute_strategy = \"mean\"\n",
    "        \n",
    "        print(f\"Using {self.impute_strategy} on {self.feature_list}\")\n",
    "        \n",
    "        if not self.impute_value:\n",
    "            if self.feature_type == \"cat\":\n",
    "                self.impute_value = \"missing\"\n",
    "            elif self.feature_type == \"num\":\n",
    "                self.impute_value = None\n",
    "            else:\n",
    "                print(\"transform(): invalid feature_type - \", self.feature_type)\n",
    "                self.impute_value = None\n",
    "            \n",
    "        try:\n",
    "            out_df = pd.DataFrame(SimpleImputer(strategy=self.impute_strategy, fill_value=self.impute_value).fit_transform(np_array), \n",
    "                                columns=self.feature_list)\n",
    "            \n",
    "            msg = f\"\\n{'='*100}\\nDfImputer.transform: Success! Imputed a DF of {X.shape} to {out_df.shape} shape.\\nFeature list: {out_df.columns}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[92m {msg}\\033[00m\")\n",
    "\n",
    "            return out_df\n",
    "        except Exception as e:\n",
    "            msg = f\"\\n{'='*100}\\nDfImputer.transform: Excpetion occurred. Please check - {e}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[91m {msg}\\033[00m\")\n",
    "            return None\n",
    "        \n",
    "class DfScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Based on: sklearn.preprocessing.StandardScaler\n",
    "    Input: pd.DataFrame of numerical features\n",
    "    Output: scaled pd.DataFrame\n",
    "    \n",
    "    This class uses sklearn StandardScaler to standardise the features of input data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Output : Pandas dataframe scaled using sklearn StandardScaler\n",
    "        \"\"\"\n",
    "#         print(\"CALLING DfScaler TRANSFORM: ***********************\", X.shape)      \n",
    "        \n",
    "        try:\n",
    "            columns = X.columns\n",
    "            np_array = X.values\n",
    "            \n",
    "            out_df = pd.DataFrame(StandardScaler().fit_transform(np_array), \n",
    "                                  columns=columns)\n",
    "            \n",
    "            msg = f\"\\n{'='*100}\\nDfScaler.transform: Success! Scaled a DF of {X.shape} to {out_df.shape} shape.\\nFeature list: {out_df.columns}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[92m {msg}\\033[00m\")\n",
    "\n",
    "            return out_df\n",
    "        except Exception as e:\n",
    "            msg = f\"\\n{'='*100}\\nDfScaler.transform: Excpetion occurred. Please check - {e}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[91m {msg}\\033[00m\")\n",
    "            return None\n",
    "        \n",
    "class DfOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Based on: sklearn.preprocessing.OneHotEncoder\n",
    "    Input: pd.DataFrame of categorical features\n",
    "    Output: One hot encoded pd.DataFrame\n",
    "    \n",
    "    This class uses sklearn OneHotEncoder to one hot encode features of input data frame and create new features with 1/0 binary values.\n",
    "    It uses - OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Output : One hot encoded Pandas dataframe created using sklearn OneHotEncoder\n",
    "        \"\"\"\n",
    "              \n",
    "        try:\n",
    "            columns = X.columns\n",
    "            np_array = X.values\n",
    "            \n",
    "            ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\", dtype=np.int)\n",
    "            \n",
    "            out_df = pd.DataFrame(ohe.fit_transform(np_array), \n",
    "                                  columns=ohe.get_feature_names(input_features=columns))\n",
    "            \n",
    "            msg = f\"\\n{'='*100}\\nDfOneHotEncoder.transform: Success! Returned a DF of {out_df.shape} shape.\\n{out_df.columns}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[92m {msg}\\033[00m\")\n",
    "            \n",
    "            return out_df\n",
    "        except Exception as e:\n",
    "            msg = f\"\\n{'='*100}\\nDfOneHotEncoder.transform: Excpetion occurred. Please check - {e}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[91m {msg}\\033[00m\")\n",
    "            return None\n",
    "        \n",
    "class DfAggregator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Aggregator class for 'previous_applications' dataset of HCDR project\n",
    "    \n",
    "    Input: pd.DataFrame \n",
    "    Output: aggregated pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key_attrib='SK_ID_CURR', count_attrib='SK_ID_PREV'):\n",
    "        self.count_attrib= count_attrib\n",
    "        self.key_attrib  = key_attrib\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Output : aggregated dataframe\n",
    "        \"\"\"\n",
    "              \n",
    "        try:\n",
    "                       \n",
    "            X = pd.concat([df_prev_app[[self.key_attrib, self.count_attrib]], X], axis=1, sort=False)\n",
    "            \n",
    "            key_attribs = ['SK_ID_CURR','SK_ID_PREV']\n",
    "            self.cat_attribs = list(X.select_dtypes(include='object').columns)\n",
    "            self.cat_attribs = [i for i in self.cat_attribs if i not in key_attribs]\n",
    "            \n",
    "            self.num_attribs = list(X.select_dtypes(exclude='object').columns)\n",
    "            self.num_attribs = [i for i in self.num_attribs if i not in key_attribs]\n",
    "        \n",
    "            self.dict_variable = {key:['mean'] for key in self.num_attribs}    \n",
    "            self.dict_variable.update({key:['sum'] for key in self.cat_attribs})\n",
    "            self.dict_variable[self.count_attrib] = ['size']\n",
    "#             print(self.dict_variable)\n",
    "            \n",
    "            out_df = X.groupby(by=self.key_attrib).agg(self.dict_variable)\n",
    "\n",
    "            out_df.columns = out_df.columns.droplevel(1)\n",
    "\n",
    "            out_df.reset_index(inplace=True)\n",
    "           \n",
    "            out_df.columns = ['COUNT_PREV_APP' if x=='SK_ID_PREV' else x for x in out_df.columns]\n",
    "        \n",
    "            msg = f\"\\n{'='*100}\\nDfAggregator.transform: Success! Aggregated a DF of {X.shape} shape to {out_df.shape}.\\nFeature list: {out_df.columns}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[92m {msg}\\033[00m\")\n",
    "\n",
    "            return out_df\n",
    "        except Exception as e:\n",
    "            msg = f\"\\n{'='*100}\\nDfAggregator.transform: Excpetion occurred. Please check - {e}\\n{'='*100}\\n\"\n",
    "            print(f\"\\033[91m {msg}\\033[00m\")\n",
    "            return None        \n",
    "        \n",
    "class DfFeatureUnion(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ### This class isn't working as expected. Please use PandasFeatureUnion instead. ###\n",
    "    \n",
    "    This class runs multiple pipelines sequentially and retuns the output in pandas dataframe format\n",
    "    \n",
    "    Input-\n",
    "    transformer_list: List of transformers\n",
    "    X: input dataframe\n",
    "    Output-\n",
    "    Pandas dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "        \n",
    "    def fit(self, X, y=None, key_cols=None):\n",
    "        \"\"\"\n",
    "        Input X: input dataframe\n",
    "        Input y: predicted feature, default=None\n",
    "        Output : class instance\n",
    "        \n",
    "        No action needed by `fit`. Returns the class instance. \n",
    "        \"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, key_cols=None):\n",
    "        \"\"\"\n",
    "        Execute each pipeline and concatenate outputs of each pipeline\n",
    "        \"\"\"\n",
    "        if key_cols:\n",
    "            self.df_out = X[key_cols]\n",
    "        else:\n",
    "            self.df_out = pd.DataFrame()\n",
    "              \n",
    "        for transformer in self.transformer_list:\n",
    "            self.df_out = pd.concat([self.df_out, transformer[1].fit_transform(X)], axis='columns')\n",
    "#         self.df_out = pd.concat([self.df_out, X], axis='columns')\n",
    "    \n",
    "        msg = f\"\\n{'='*100}\\nDfFeatureUnion.transform: Success! Returned a DF of {self.df_out.shape} shape.\\n{self.df_out.columns}\\n{'='*100}\\n\"\n",
    "        print(f\"\\033[92m {msg}\\033[00m\")    \n",
    "            \n",
    "        return self.df_out\n",
    "    \n",
    "    def fit_transform(self, X, key_cols=None):\n",
    "        \"\"\"\n",
    "        Custom fit_transform method\n",
    "        \"\"\"\n",
    "        return self.transform(X, key_cols)\n",
    "    \n",
    "    \n",
    "# Source: https://zablo.net/blog/post/pandas-dataframe-in-scikit-learn-feature-union/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.pipeline import FeatureUnion, _fit_transform_one, _transform_one\n",
    "from scipy import sparse\n",
    "\n",
    "class PandasFeatureUnion(FeatureUnion):\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self._validate_transformers()\n",
    "        result = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_transform_one)(\n",
    "                transformer=trans,\n",
    "                X=X,\n",
    "                y=y,\n",
    "                weight=weight,\n",
    "                **fit_params)\n",
    "            for name, trans, weight in self._iter())\n",
    "\n",
    "        if not result:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        Xs, transformers = zip(*result)\n",
    "        self._update_transformer_list(transformers)\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            # this handles df\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs\n",
    "\n",
    "    def merge_dataframes_by_column(self, Xs):\n",
    "        return pd.concat(Xs, axis=\"columns\", copy=False)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xs = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_transform_one)(\n",
    "                transformer=trans,\n",
    "                X=X,\n",
    "                y=None,\n",
    "                weight=weight)\n",
    "            for name, trans, weight in self._iter())\n",
    "        if not Xs:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            # this handles df\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipelines(df, key_attribs=['SK_ID_CURR', 'SK_ID_PREV'], verbose=False):\n",
    "    num_attribs = list(df.select_dtypes(exclude='object').columns)\n",
    "    num_attribs = [i for i in num_attribs if i not in key_attribs]\n",
    "    \n",
    "    cat_attribs = list(df.select_dtypes(include='object').columns)\n",
    "    cat_attribs = [i for i in cat_attribs if i not in key_attribs]\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"num: \", num_attribs)\n",
    "        print(\"cat: \", cat_attribs)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('df_imputer', DfImputer('num')),\n",
    "            ('df_std_scaler', DfScaler()),\n",
    "        ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "            ('df_imputer', DfImputer('cat')),\n",
    "            ('df_ohe', DfOneHotEncoder()),\n",
    "        ])\n",
    "\n",
    "    df_data_prep_pipeline = PandasFeatureUnion(transformer_list=[\n",
    "            (\"num_pipeline\", num_pipeline),\n",
    "            (\"cat_pipeline\", cat_pipeline),\n",
    "        ])    \n",
    "\n",
    "# ColumnTransformer did not work    \n",
    "#     df_data_prep_pipeline = ColumnTransformer( \n",
    "#                                 transformers= [\n",
    "#                                                 # (name, transformer,     columns)\n",
    "#                                                 (\"num_pipeline\", num_pipeline, num_attribs),\n",
    "# #                                                 (\"cat_pipeline\", cat_pipeline, cat_attribs),    \n",
    "#                                               ],\n",
    "#                                 remainder='drop',\n",
    "#                                 n_jobs=-1\n",
    "#                             )\n",
    "    if verbose == True:\n",
    "        print(\"\\033[92mSuccess! Pipeline created:\\033[00m\")\n",
    "        print(df_data_prep_pipeline)     \n",
    "    \n",
    "    return df_data_prep_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfFeatureAdder.transform: Success! Transformed DF of (1670214, 37) to (1670214, 13) shape.\n",
      "Feature list: ['SK_ID_PREV', 'SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'NAME_CONTRACT_STATUS', 'DAYS_DECISION', 'NAME_PORTFOLIO', 'CREDIT_TO_APP_RATIO', 'APPLIED_EXTRA', 'WEEKDAY', 'TIME']\n",
      "====================================================================================================\n",
      "\u001b[00m\n",
      "Using mean on ['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'DAYS_DECISION', 'CREDIT_TO_APP_RATIO']\n",
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfImputer.transform: Success! Imputed a DF of (1670214, 13) to (1670214, 5) shape.\n",
      "Feature list: Index(['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'DAYS_DECISION',\n",
      "       'CREDIT_TO_APP_RATIO'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "\u001b[00m\n",
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfScaler.transform: Success! Scaled a DF of (1670214, 5) to (1670214, 5) shape.\n",
      "Feature list: Index(['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'DAYS_DECISION',\n",
      "       'CREDIT_TO_APP_RATIO'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "\u001b[00m\n",
      "Using constant on ['NAME_CONTRACT_TYPE', 'NAME_CONTRACT_STATUS', 'NAME_PORTFOLIO', 'APPLIED_EXTRA', 'WEEKDAY', 'TIME']\n",
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfImputer.transform: Success! Imputed a DF of (1670214, 13) to (1670214, 6) shape.\n",
      "Feature list: Index(['NAME_CONTRACT_TYPE', 'NAME_CONTRACT_STATUS', 'NAME_PORTFOLIO',\n",
      "       'APPLIED_EXTRA', 'WEEKDAY', 'TIME'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "\u001b[00m\n",
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfOneHotEncoder.transform: Success! Returned a DF of (1670214, 22) shape.\n",
      "Index(['NAME_CONTRACT_TYPE_Cash loans', 'NAME_CONTRACT_TYPE_Consumer loans',\n",
      "       'NAME_CONTRACT_TYPE_Revolving loans', 'NAME_CONTRACT_TYPE_XNA',\n",
      "       'NAME_CONTRACT_STATUS_Approved', 'NAME_CONTRACT_STATUS_Canceled',\n",
      "       'NAME_CONTRACT_STATUS_Refused', 'NAME_CONTRACT_STATUS_Unused offer',\n",
      "       'NAME_PORTFOLIO_Cards', 'NAME_PORTFOLIO_Cars', 'NAME_PORTFOLIO_Cash',\n",
      "       'NAME_PORTFOLIO_POS', 'NAME_PORTFOLIO_XNA', 'APPLIED_EXTRA_0',\n",
      "       'APPLIED_EXTRA_1', 'WEEKDAY_END', 'WEEKDAY_MID', 'WEEKDAY_START',\n",
      "       'TIME_AFTERNOON', 'TIME_EARLY_MORN', 'TIME_EVENING', 'TIME_MORN'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "\u001b[00m\n",
      "\u001b[92m \n",
      "====================================================================================================\n",
      "DfAggregator.transform: Success! Aggregated a DF of (1670214, 29) shape to (338857, 29).\n",
      "Feature list: Index(['SK_ID_CURR', 'AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT',\n",
      "       'DAYS_DECISION', 'CREDIT_TO_APP_RATIO', 'NAME_CONTRACT_TYPE_Cash loans',\n",
      "       'NAME_CONTRACT_TYPE_Consumer loans',\n",
      "       'NAME_CONTRACT_TYPE_Revolving loans', 'NAME_CONTRACT_TYPE_XNA',\n",
      "       'NAME_CONTRACT_STATUS_Approved', 'NAME_CONTRACT_STATUS_Canceled',\n",
      "       'NAME_CONTRACT_STATUS_Refused', 'NAME_CONTRACT_STATUS_Unused offer',\n",
      "       'NAME_PORTFOLIO_Cards', 'NAME_PORTFOLIO_Cars', 'NAME_PORTFOLIO_Cash',\n",
      "       'NAME_PORTFOLIO_POS', 'NAME_PORTFOLIO_XNA', 'APPLIED_EXTRA_0',\n",
      "       'APPLIED_EXTRA_1', 'WEEKDAY_END', 'WEEKDAY_MID', 'WEEKDAY_START',\n",
      "       'TIME_AFTERNOON', 'TIME_EARLY_MORN', 'TIME_EVENING', 'TIME_MORN',\n",
      "       'COUNT_PREV_APP'],\n",
      "      dtype='object')\n",
      "====================================================================================================\n",
      "\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>DAYS_DECISION</th>\n",
       "      <th>CREDIT_TO_APP_RATIO</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Consumer loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>NAME_CONTRACT_TYPE_XNA</th>\n",
       "      <th>...</th>\n",
       "      <th>APPLIED_EXTRA_0</th>\n",
       "      <th>APPLIED_EXTRA_1</th>\n",
       "      <th>WEEKDAY_END</th>\n",
       "      <th>WEEKDAY_MID</th>\n",
       "      <th>WEEKDAY_START</th>\n",
       "      <th>TIME_AFTERNOON</th>\n",
       "      <th>TIME_EARLY_MORN</th>\n",
       "      <th>TIME_EVENING</th>\n",
       "      <th>TIME_MORN</th>\n",
       "      <th>COUNT_PREV_APP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>-0.921182</td>\n",
       "      <td>-0.513691</td>\n",
       "      <td>-0.514129</td>\n",
       "      <td>-1.102966</td>\n",
       "      <td>-0.547329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100002</td>\n",
       "      <td>-0.514407</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>-0.025888</td>\n",
       "      <td>0.352560</td>\n",
       "      <td>-0.228399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100003</td>\n",
       "      <td>3.115510</td>\n",
       "      <td>0.888732</td>\n",
       "      <td>0.933614</td>\n",
       "      <td>-0.544629</td>\n",
       "      <td>0.207220</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100004</td>\n",
       "      <td>-0.813268</td>\n",
       "      <td>-0.515582</td>\n",
       "      <td>-0.525704</td>\n",
       "      <td>0.084302</td>\n",
       "      <td>-1.527598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100005</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>-0.522321</td>\n",
       "      <td>-0.525796</td>\n",
       "      <td>0.442408</td>\n",
       "      <td>-0.492110</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  AMT_ANNUITY  AMT_APPLICATION  AMT_CREDIT  DAYS_DECISION  \\\n",
       "0      100001    -0.921182        -0.513691   -0.514129      -1.102966   \n",
       "1      100002    -0.514407         0.013051   -0.025888       0.352560   \n",
       "2      100003     3.115510         0.888732    0.933614      -0.544629   \n",
       "3      100004    -0.813268        -0.515582   -0.525704       0.084302   \n",
       "4      100005    -0.427509        -0.522321   -0.525796       0.442408   \n",
       "\n",
       "   CREDIT_TO_APP_RATIO  NAME_CONTRACT_TYPE_Cash loans  \\\n",
       "0            -0.547329                       0.000000   \n",
       "1            -0.228399                       0.000000   \n",
       "2             0.207220                       0.333333   \n",
       "3            -1.527598                       0.000000   \n",
       "4            -0.492110                       0.500000   \n",
       "\n",
       "   NAME_CONTRACT_TYPE_Consumer loans  NAME_CONTRACT_TYPE_Revolving loans  \\\n",
       "0                           1.000000                                 0.0   \n",
       "1                           1.000000                                 0.0   \n",
       "2                           0.666667                                 0.0   \n",
       "3                           1.000000                                 0.0   \n",
       "4                           0.500000                                 0.0   \n",
       "\n",
       "   NAME_CONTRACT_TYPE_XNA  ...  APPLIED_EXTRA_0  APPLIED_EXTRA_1  WEEKDAY_END  \\\n",
       "0                     0.0  ...              1.0              0.0     0.000000   \n",
       "1                     0.0  ...              1.0              0.0     1.000000   \n",
       "2                     0.0  ...              1.0              0.0     0.666667   \n",
       "3                     0.0  ...              1.0              0.0     0.000000   \n",
       "4                     0.0  ...              1.0              0.0     0.000000   \n",
       "\n",
       "   WEEKDAY_MID  WEEKDAY_START  TIME_AFTERNOON  TIME_EARLY_MORN  TIME_EVENING  \\\n",
       "0     1.000000            0.0        1.000000              0.0           0.0   \n",
       "1     0.000000            0.0        0.000000              0.0           0.0   \n",
       "2     0.333333            0.0        0.666667              0.0           0.0   \n",
       "3     1.000000            0.0        0.000000              1.0           0.0   \n",
       "4     1.000000            0.0        0.000000              0.0           0.0   \n",
       "\n",
       "   TIME_MORN  COUNT_PREV_APP  \n",
       "0   0.000000               1  \n",
       "1   1.000000               1  \n",
       "2   0.333333               3  \n",
       "3   0.000000               1  \n",
       "4   1.000000               2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Features selected by looking at the data\n",
    "selected_features = ['SK_ID_PREV','SK_ID_CURR','NAME_CONTRACT_TYPE','AMT_ANNUITY','AMT_APPLICATION','AMT_CREDIT',\n",
    "                     'AMT_GOODS_PRICE','WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START',\n",
    "                     'NAME_CONTRACT_STATUS','DAYS_DECISION','NAME_PORTFOLIO']\n",
    "\n",
    "# New DF for selected and engineered features\n",
    "df_selected = DfFeatureAdder(selected_features).fit_transform(df_prev_app)\n",
    "\n",
    "# Pipeline creation\n",
    "df_data_prep_pipeline = create_pipelines(df_selected, verbose=False)\n",
    "\n",
    "# Execute pipe lines on above DF\n",
    "df_transformed = df_data_prep_pipeline.fit_transform(df_selected)\n",
    "\n",
    "# Aggregate data on SK_ID_CURR\n",
    "df_agg = DfAggregator().fit_transform(df_transformed)\n",
    "\n",
    "display(df_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216.08px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
